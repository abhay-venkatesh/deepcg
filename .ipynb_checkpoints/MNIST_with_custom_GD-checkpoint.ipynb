{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from numpy import linalg as LA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(10), Dimension(None)])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[784, None])\n",
    "y_true = tf.placeholder(tf.float32, shape=[10, None])\n",
    "W = tf.Variable(tf.zeros([10,784]))\n",
    "b = tf.Variable(tf.zeros([10,1]))\n",
    "y_pred = tf.matmul(W, x) + b\n",
    "y_pred.get_shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_true, logits=y_pred))\n",
    "# optimzr = tf.train.AdamOptimizer(1e-4).minimize(loss)\n",
    "\n",
    "# correct_prediction = tf.equal(tf.argmax(y_pred, 0), tf.argmax(y_true, 0))\n",
    "# accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tf_frobenius_norm(M):\n",
    "    return tf.reduce_sum(M ** 2) ** 0.5\n",
    "\n",
    "# to implement nuclear norm\n",
    "def tf_nuclear_norm(M):\n",
    "    return 1\n",
    "\n",
    "def Cgd_Fn(grad, wt):\n",
    "    return ((1 - alpha ) / alpha) * (wt - lam1 * grad / tf_frobenius_norm(grad))\n",
    "\n",
    "def Cgd_Nn(grad, wt):\n",
    "    return ((1 - alpha ) / alpha) * (wt - lam2 * tf_nuclear_norm(grad))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_true, logits=y_pred))\n",
    "\n",
    "# hyper-parameters\n",
    "alpha = tf.placeholder_with_default(tf.constant(0.5), tf.constant(0.5).shape)\n",
    "lam1 = tf.placeholder_with_default(tf.constant(100.0), tf.constant(100.0).shape)\n",
    "lam2 = tf.placeholder_with_default(tf.constant(100.0), tf.constant(100.0).shape)\n",
    "\n",
    "# Gradient Descent optimizer\n",
    "opt = tf.train.GradientDescentOptimizer(learning_rate = alpha)\n",
    "\n",
    "# Compute the gradients for a list of variables.\n",
    "grads_and_vars = opt.compute_gradients(loss)\n",
    "\n",
    "# Normal GD update\n",
    "gv = [(gv[0], gv[1]) for gv in grads_and_vars]\n",
    "optimizer_gv = opt.apply_gradients(gv)\n",
    "\n",
    "# CGD with FN\n",
    "gv_cgd_fn = [(Cgd_Fn(gv[0], gv[1]), gv[1]) for gv in grads_and_vars]\n",
    "optimizer_gv_cgd_fn = opt.apply_gradients(gv_cgd_fn)\n",
    "a = gv[0][0]\n",
    "b = tf_frobenius_norm(gv[0][0])\n",
    "c = gv[0][0] / tf_frobenius_norm(gv[0][0])\n",
    "\n",
    "# CGD with NN\n",
    "gv_cgd_nn = [(Cgd_Nn(gv[0], gv[1]), gv[1]) for gv in grads_and_vars]\n",
    "optimizer_gv_cgd_Nn = opt.apply_gradients(gv_cgd_nn)\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(y_pred, 0), tf.argmax(y_true, 0))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_accuracy 0.12 46.0517\n",
      "frob_nrom 20.7361\n",
      "train_accuracy 0.1 46.0517\n",
      "frob_nrom 20.7243\n",
      "train_accuracy 0.09 46.0517\n",
      "frob_nrom 20.9994\n",
      "train_accuracy 0.13 46.0517\n",
      "frob_nrom 23.4502\n",
      "train_accuracy 0.07 46.0517\n",
      "frob_nrom 22.6326\n",
      "train_accuracy 0.1 46.0517\n",
      "frob_nrom 21.6722\n",
      "train_accuracy 0.11 46.0517\n",
      "frob_nrom 20.9075\n",
      "train_accuracy 0.04 46.0517\n",
      "frob_nrom 21.3595\n",
      "train_accuracy 0.1 46.0517\n",
      "frob_nrom 21.5441\n",
      "train_accuracy 0.08 46.0517\n",
      "frob_nrom 21.3968\n",
      "test_accuracy 0.098\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in range(1000):\n",
    "        batch = mnist.train.next_batch(100)\n",
    "        feed_dict = {x: np.transpose(batch[0]), y_true: np.transpose(batch[1]), alpha: 1}\n",
    "        train_accuracy, loss_, grads_, W_ = sess.run([accuracy, loss, gv_cgd_fn, W], feed_dict)\n",
    "        a_,b_,c_ = sess.run([a,b,c], feed_dict)\n",
    "            \n",
    "        if i % 100 == 0:\n",
    "            print('train_accuracy', train_accuracy, loss_)\n",
    "            print('frob_nrom', b_)\n",
    "        sess.run(optimizer_gv_cgd_fn, feed_dict)\n",
    "    \n",
    "    feed_dict={x: np.transpose(mnist.test.images), y_true: np.transpose(mnist.test.labels), alpha: 0.1}\n",
    "    test_accuracy = sess.run(accuracy, feed_dict)\n",
    "    print('test_accuracy', test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.framework.ops.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "print(type(grads_and_vars[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  4],\n",
       "       [ 9, 16],\n",
       "       [25, 36]], dtype=int32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.constant([[1,2],[3,4],[5,6]])\n",
    "b = a**2\n",
    "tf.Session().run(b)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
