{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from numpy import linalg as LA\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(10), Dimension(None)])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[784, None])\n",
    "y_true = tf.placeholder(tf.float32, shape=[10, None])\n",
    "W = tf.Variable(tf.zeros([10,784]))\n",
    "# b = tf.Variable(tf.zeros([10,1]))\n",
    "y_pred = tf.matmul(W, x) \n",
    "y_pred.get_shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def tf_frobenius_norm(M):\n",
    "    return tf.reduce_sum(M ** 2) ** 0.5\n",
    "\n",
    "# to implement nuclear norm\n",
    "def tf_nuclear_norm(M):\n",
    "    st, ut, vt = tf.svd(M,  full_matrices = False)\n",
    "    st2 = tf.diag(st)\n",
    "    st_r = tf.matmul(ut, tf.matmul(st2, tf.transpose(vt)))\n",
    "    print('vish', ut.shape, st2.shape, tf.transpose(vt).shape, st_r.shape)\n",
    "    \n",
    "    uk = tf.reshape(ut[:, 0], [10, 1])\n",
    "    vk = tf.reshape(vt[:, 0], [1, 784])\n",
    "    sk = tf.matmul(uk, vk)\n",
    "    sk = st[0] * sk\n",
    "    print(st.shape, ut.shape, vt.shape)\n",
    "    print('before', type(sk), sk.shape)\n",
    "    return sk, st[0], st_r, M\n",
    "\n",
    "# def tf_nuclear_norm_pm(M):\n",
    "#     un = np.zeros([10, 1])\n",
    "#     un[0][0] = 1\n",
    "#     u = tf.constant(un)\n",
    "#     vn = np.zeros([1, 784])\n",
    "#     vn[0][0] = 1\n",
    "#     v = tf.constant(vn)\n",
    "#     for _ in range(20): \n",
    "#         u = tf.matmul(M, x)\n",
    "#         v = tf.\n",
    "\n",
    "def Sgdnm(grad, wt):\n",
    "    return (grad / tf_frobenius_norm(grad))\n",
    "\n",
    "def Cgd_Fn(grad, wt):\n",
    "    return ((1 - alpha ) / alpha) * (wt + lam1 * grad / tf_frobenius_norm(grad))\n",
    "\n",
    "def Cgd_Nn(grad, wt):\n",
    "    nn, st, st_r, M = tf_nuclear_norm(grad)\n",
    "    return ((1 - alpha ) / alpha) * (wt - lam2 * nn), st, st_r, M\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vish (10, 10) (10, 10) (10, 784) (10, 784)\n",
      "(10,) (10, 10) (784, 10)\n",
      "before <class 'tensorflow.python.framework.ops.Tensor'> (10, 784)\n"
     ]
    }
   ],
   "source": [
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_true, logits=y_pred))\n",
    "\n",
    "# hyper-parameters\n",
    "# alpha = tf.placeholder_with_default(tf.constant(0.5), tf.constant(0.001).shape)\n",
    "global_step = tf.Variable(0, trainable=False)\n",
    "start_train = 0.9999 # Requires very high lambda for Cgd_Fn\n",
    "# k=1, start_train = 1, decay_rate = 1 ---> 1/t learning rate\n",
    "k = 1\n",
    "alpha = tf.train.inverse_time_decay(start_train, global_step, k, 0)\n",
    "lam1 = tf.placeholder_with_default(tf.constant(4.0), tf.constant(10000.0).shape)\n",
    "lam2 = tf.placeholder_with_default(tf.constant(4.0), tf.constant(100.0).shape)\n",
    "\n",
    "# Gradient Descent optimizer\n",
    "opt = tf.train.GradientDescentOptimizer(learning_rate = alpha)\n",
    "\n",
    "# Compute the gradients for a list of variables.\n",
    "grads_and_vars = opt.compute_gradients(loss)\n",
    "\n",
    "# SGD update\n",
    "gv_sgd = [(gv[0], gv[1]) for gv in grads_and_vars]\n",
    "optimizer_gv_sgd = opt.apply_gradients(gv_sgd, global_step=global_step)\n",
    "g0_sgd = grads_and_vars[0][0]\n",
    "w0_sgd = grads_and_vars[0][1]\n",
    "s0_sgd = w0_sgd\n",
    "w1_sgd = w0_sgd - alpha * s0_sgd\n",
    "\n",
    "\n",
    "# Normalized SGD update\n",
    "gv_nsgd = [(Sgdnm(gv[0], gv[1]), gv[1]) for gv in grads_and_vars]\n",
    "optimizer_gv_nsgd = opt.apply_gradients(gv_nsgd, global_step=global_step)\n",
    "g0_nsgd = grads_and_vars[0][0]\n",
    "w0_nsgd = grads_and_vars[0][1]\n",
    "s0_nsgd = Sgdnm(g0_nsgd, w0_nsgd)\n",
    "w1_nsgd = w0_nsgd - alpha * s0_nsgd\n",
    "\n",
    "\n",
    "# CGD with FN\n",
    "gv_cgd_fn = [(Cgd_Fn(gv[0], gv[1]), gv[1]) for gv in grads_and_vars]\n",
    "optimizer_gv_cgd_fn = opt.apply_gradients(gv_cgd_fn, global_step=global_step)\n",
    "g0_cgd_fn = grads_and_vars[0][0]\n",
    "w0_cgd_fn = grads_and_vars[0][1]\n",
    "s0_cgd_fn = Cgd_Fn(g0_cgd_fn, w0_cgd_fn)\n",
    "w1_cgd_fn = w0_cgd_fn - alpha * s0_cgd_fn\n",
    "\n",
    "# CGD with NN\n",
    "g0_cgd_nn = grads_and_vars[0][0]\n",
    "w0_cgd_nn = grads_and_vars[0][1]\n",
    "s0_cgd_nn, st, st_r, M = Cgd_Nn(g0_cgd_nn, w0_cgd_nn)\n",
    "gv_cgd_nn = [(s0_cgd_nn, gv[1]) for gv in grads_and_vars]\n",
    "optimizer_gv_cgd_nn = opt.apply_gradients(gv_cgd_nn, global_step=global_step)\n",
    "w1_cgd_nn = w0_cgd_nn - alpha * s0_cgd_nn\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(y_pred, 0), tf.argmax(y_true, 0))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalized gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# with tf.Session() as sess:\n",
    "#     sess.run(tf.global_variables_initializer())\n",
    "#     for i in range(1000):\n",
    "#         batch = mnist.train.next_batch(100)\n",
    "#         feed_dict = {x: np.transpose(batch[0]), y_true: np.transpose(batch[1])}\n",
    "#         train_accuracy, loss_, gv_, W_ = sess.run([accuracy, loss, gv_nsgd, W], feed_dict)\n",
    "#         w1_nsgd_, w0_nsgd_, s0_nsgd_= sess.run([w1_nsgd, w0_nsgd, s0_nsgd], feed_dict)\n",
    "#         alpha_ = sess.run([alpha], feed_dict)\n",
    "            \n",
    "#         if i % 1 == 0:\n",
    "#             print('train_accuracy=', train_accuracy, 'loss=', loss_)\n",
    "#             print('NSgd iterates: w(t+1) =', LA.norm(w1_nsgd_), 'w(t) =', LA.norm(w0_nsgd_), 's(t) =', LA.norm(s0_nsgd_))\n",
    "#             print('alpha', alpha_)\n",
    "#         sess.run(optimizer_gv_nsgd, feed_dict)\n",
    "    \n",
    "#     feed_dict={x: np.transpose(mnist.test.images), y_true: np.transpose(mnist.test.labels)}\n",
    "#     test_accuracy = sess.run(accuracy, feed_dict)\n",
    "#     print('test_accuracy=', test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Frobenius norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# with tf.Session() as sess:\n",
    "#     sess.run(tf.global_variables_initializer())\n",
    "#     for i in range(1000):\n",
    "#         batch = mnist.train.next_batch(100)\n",
    "#         batch1 = batch[:]\n",
    "#         feed_dict = {x: np.transpose(batch[0]), y_true: np.transpose(batch[1])}\n",
    "#         train_accuracy, loss_, gv_, W1_ = sess.run([accuracy, loss, gv_cgd_fn, W], feed_dict)\n",
    "#         w1_cgd_fn_, w0_cgd_fn_, s0_cgd_fn_ = sess.run([w1_cgd_fn, w0_cgd_fn, s0_cgd_fn], feed_dict)\n",
    "#         alpha_ = sess.run([alpha], feed_dict)\n",
    "            \n",
    "#         if i % 100 == 0:\n",
    "#             print('train_accuracy=', train_accuracy, 'loss value =',loss_)\n",
    "#             print('frob_nrom of iterates: w(t+1) =', LA.norm(w1_cgd_fn_), 'w(t) =', LA.norm(w0_cgd_fn_), 's(t) =', LA.norm(s0_cgd_fn_))\n",
    "#             print('alpha', alpha_)\n",
    "#         sess.run(optimizer_gv_cgd_fn, feed_dict)\n",
    "    \n",
    "#     feed_dict={x: np.transpose(mnist.test.images), y_true: np.transpose(mnist.test.labels)}\n",
    "#     test_accuracy = sess.run(accuracy, feed_dict)\n",
    "#     print('test_accuracy', test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Nuclear Norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_accuracy= 0.08 loss value = 46.0517\n",
      "nuclear_norm of iterates: w(t+1) = 0.0065515 w(t) = 0.0 s(t) = 0.00655215\n",
      "alpha [0.99989998]\n",
      "train_accuracy= 0.09 loss value = 46.0517\n",
      "nuclear_norm of iterates: w(t+1) = 0.0139243 w(t) = 0.0065515 s(t) = 0.00784853\n",
      "alpha [0.99989998]\n",
      "train_accuracy= 0.13 loss value = 46.0607\n",
      "nuclear_norm of iterates: w(t+1) = 0.0203266 w(t) = 0.0139243 s(t) = 0.00657983\n",
      "alpha [0.99989998]\n",
      "train_accuracy= 0.09 loss value = 46.063\n",
      "nuclear_norm of iterates: w(t+1) = 0.0265976 w(t) = 0.0203266 s(t) = 0.00652477\n",
      "alpha [0.99989998]\n",
      "train_accuracy= 0.09 loss value = 46.0657\n",
      "nuclear_norm of iterates: w(t+1) = 0.0324852 w(t) = 0.0265976 s(t) = 0.00627808\n",
      "alpha [0.99989998]\n",
      "train_accuracy= 0.09 loss value = 46.071\n",
      "nuclear_norm of iterates: w(t+1) = 0.0380327 w(t) = 0.0324852 s(t) = 0.00591359\n",
      "alpha [0.99989998]\n",
      "train_accuracy= 0.16 loss value = 46.07\n",
      "nuclear_norm of iterates: w(t+1) = 0.0439815 w(t) = 0.0380327 s(t) = 0.00637539\n",
      "alpha [0.99989998]\n",
      "train_accuracy= 0.09 loss value = 46.0728\n",
      "nuclear_norm of iterates: w(t+1) = 0.050015 w(t) = 0.0439815 s(t) = 0.00670879\n",
      "alpha [0.99989998]\n",
      "train_accuracy= 0.05 loss value = 46.0837\n",
      "nuclear_norm of iterates: w(t+1) = 0.056569 w(t) = 0.050015 s(t) = 0.00714487\n",
      "alpha [0.99989998]\n",
      "train_accuracy= 0.1 loss value = 46.0771\n",
      "nuclear_norm of iterates: w(t+1) = 0.0631429 w(t) = 0.056569 s(t) = 0.00723009\n",
      "alpha [0.99989998]\n",
      "train_accuracy= 0.08 loss value = 46.0945\n",
      "nuclear_norm of iterates: w(t+1) = 0.0703775 w(t) = 0.0631429 s(t) = 0.00749681\n",
      "alpha [0.99989998]\n",
      "train_accuracy= 0.09 loss value = 46.1082\n",
      "nuclear_norm of iterates: w(t+1) = 0.0778187 w(t) = 0.0703775 s(t) = 0.00775341\n",
      "alpha [0.99989998]\n",
      "train_accuracy= 0.08 loss value = 46.1091\n",
      "nuclear_norm of iterates: w(t+1) = 0.085228 w(t) = 0.0778187 s(t) = 0.00799678\n",
      "alpha [0.99989998]\n",
      "train_accuracy= 0.04 loss value = 46.1157\n",
      "nuclear_norm of iterates: w(t+1) = 0.0915654 w(t) = 0.085228 s(t) = 0.00688637\n",
      "alpha [0.99989998]\n",
      "train_accuracy= 0.13 loss value = 46.1174\n",
      "nuclear_norm of iterates: w(t+1) = 0.0984038 w(t) = 0.0915654 s(t) = 0.00735599\n",
      "alpha [0.99989998]\n",
      "train_accuracy= 0.09 loss value = 46.1482\n",
      "nuclear_norm of iterates: w(t+1) = 0.105765 w(t) = 0.0984038 s(t) = 0.0081109\n",
      "alpha [0.99989998]\n",
      "train_accuracy= 0.09 loss value = 46.1396\n",
      "nuclear_norm of iterates: w(t+1) = 0.113134 w(t) = 0.105765 s(t) = 0.00810983\n",
      "alpha [0.99989998]\n",
      "train_accuracy= 0.11 loss value = 46.1744\n",
      "nuclear_norm of iterates: w(t+1) = 0.121059 w(t) = 0.113134 s(t) = 0.00840224\n",
      "alpha [0.99989998]\n",
      "train_accuracy= 0.09 loss value = 46.1688\n",
      "nuclear_norm of iterates: w(t+1) = 0.128836 w(t) = 0.121059 s(t) = 0.00823259\n",
      "alpha [0.99989998]\n",
      "train_accuracy= 0.12 loss value = 46.1058\n",
      "nuclear_norm of iterates: w(t+1) = 0.135782 w(t) = 0.128836 s(t) = 0.0073967\n",
      "alpha [0.99989998]\n",
      "train_accuracy= 0.04 loss value = 46.1312\n",
      "nuclear_norm of iterates: w(t+1) = 0.142535 w(t) = 0.135782 s(t) = 0.00763358\n",
      "alpha [0.99989998]\n",
      "train_accuracy= 0.08 loss value = 46.14\n",
      "nuclear_norm of iterates: w(t+1) = 0.149031 w(t) = 0.142535 s(t) = 0.00696351\n",
      "alpha [0.99989998]\n",
      "train_accuracy= 0.1 loss value = 46.1403\n",
      "nuclear_norm of iterates: w(t+1) = 0.155713 w(t) = 0.149031 s(t) = 0.0072986\n",
      "alpha [0.99989998]\n",
      "train_accuracy= 0.08 loss value = 46.1425\n",
      "nuclear_norm of iterates: w(t+1) = 0.161698 w(t) = 0.155713 s(t) = 0.00631206\n",
      "alpha [0.99989998]\n",
      "train_accuracy= 0.08 loss value = 46.1736\n",
      "nuclear_norm of iterates: w(t+1) = 0.167692 w(t) = 0.161698 s(t) = 0.00646226\n",
      "alpha [0.99989998]\n",
      "train_accuracy= 0.18 loss value = 46.1602\n",
      "nuclear_norm of iterates: w(t+1) = 0.174402 w(t) = 0.167692 s(t) = 0.00740267\n",
      "alpha [0.99989998]\n",
      "train_accuracy= 0.06 loss value = 46.1593\n",
      "nuclear_norm of iterates: w(t+1) = 0.181265 w(t) = 0.174402 s(t) = 0.00785663\n",
      "alpha [0.99989998]\n",
      "train_accuracy= 0.07 loss value = 46.1625\n",
      "nuclear_norm of iterates: w(t+1) = 0.187767 w(t) = 0.181265 s(t) = 0.00707974\n",
      "alpha [0.99989998]\n",
      "train_accuracy= 0.11 loss value = 46.177\n",
      "nuclear_norm of iterates: w(t+1) = 0.194302 w(t) = 0.187767 s(t) = 0.00785716\n",
      "alpha [0.99989998]\n",
      "train_accuracy= 0.0 loss value = 46.2066\n",
      "nuclear_norm of iterates: w(t+1) = 0.201472 w(t) = 0.194302 s(t) = 0.0075841\n",
      "alpha [0.99989998]\n",
      "train_accuracy= 0.03 loss value = 46.2064\n",
      "nuclear_norm of iterates: w(t+1) = 0.208233 w(t) = 0.201472 s(t) = 0.007107\n",
      "alpha [0.99989998]\n",
      "train_accuracy= 0.12 loss value = 46.2206\n",
      "nuclear_norm of iterates: w(t+1) = 0.214832 w(t) = 0.208233 s(t) = 0.00690878\n",
      "alpha [0.99989998]\n",
      "train_accuracy= 0.06 loss value = 46.2618\n",
      "nuclear_norm of iterates: w(t+1) = 0.221999 w(t) = 0.214832 s(t) = 0.00745737\n",
      "alpha [0.99989998]\n",
      "train_accuracy= 0.13 loss value = 46.244\n",
      "nuclear_norm of iterates: w(t+1) = 0.228195 w(t) = 0.221999 s(t) = 0.00666476\n",
      "alpha [0.99989998]\n",
      "train_accuracy= 0.07 loss value = 46.4303\n",
      "nuclear_norm of iterates: w(t+1) = 0.237688 w(t) = 0.228195 s(t) = 0.0103927\n",
      "alpha [0.99989998]\n",
      "train_accuracy= 0.12 loss value = 46.2535\n",
      "nuclear_norm of iterates: w(t+1) = 0.245272 w(t) = 0.237688 s(t) = 0.00779976\n",
      "alpha [0.99989998]\n",
      "train_accuracy= 0.09 loss value = 46.2583\n",
      "nuclear_norm of iterates: w(t+1) = 0.252823 w(t) = 0.245272 s(t) = 0.00787462\n",
      "alpha [0.99989998]\n",
      "train_accuracy= 0.13 loss value = 46.3298\n",
      "nuclear_norm of iterates: w(t+1) = 0.259991 w(t) = 0.252823 s(t) = 0.00740999\n",
      "alpha [0.99989998]\n",
      "train_accuracy= 0.14 loss value = 46.2551\n",
      "nuclear_norm of iterates: w(t+1) = 0.265977 w(t) = 0.259991 s(t) = 0.00680032\n",
      "alpha [0.99989998]\n",
      "train_accuracy= 0.05 loss value = 46.2603\n",
      "nuclear_norm of iterates: w(t+1) = 0.272686 w(t) = 0.265977 s(t) = 0.00720883\n",
      "alpha [0.99989998]\n",
      "train_accuracy= 0.13 loss value = 46.3558\n",
      "nuclear_norm of iterates: w(t+1) = 0.280103 w(t) = 0.272686 s(t) = 0.00775662\n",
      "alpha [0.99989998]\n",
      "train_accuracy= 0.1 loss value = 46.3442\n",
      "nuclear_norm of iterates: w(t+1) = 0.287425 w(t) = 0.280103 s(t) = 0.00763227\n",
      "alpha [0.99989998]\n",
      "train_accuracy= 0.12 loss value = 46.4033\n",
      "nuclear_norm of iterates: w(t+1) = 0.295089 w(t) = 0.287425 s(t) = 0.00839612\n",
      "alpha [0.99989998]\n",
      "train_accuracy= 0.09 loss value = 46.3066\n",
      "nuclear_norm of iterates: w(t+1) = 0.301805 w(t) = 0.295089 s(t) = 0.00730092\n",
      "alpha [0.99989998]\n",
      "train_accuracy= 0.18 loss value = 46.378\n",
      "nuclear_norm of iterates: w(t+1) = 0.308412 w(t) = 0.301805 s(t) = 0.00714121\n",
      "alpha [0.99989998]\n",
      "train_accuracy= 0.13 loss value = 46.3355\n",
      "nuclear_norm of iterates: w(t+1) = 0.315319 w(t) = 0.308412 s(t) = 0.00727009\n",
      "alpha [0.99989998]\n",
      "train_accuracy= 0.09 loss value = 46.2758\n",
      "nuclear_norm of iterates: w(t+1) = 0.321938 w(t) = 0.315319 s(t) = 0.00695008\n",
      "alpha [0.99989998]\n",
      "train_accuracy= 0.12 loss value = 46.2721\n",
      "nuclear_norm of iterates: w(t+1) = 0.328437 w(t) = 0.321938 s(t) = 0.00701679\n",
      "alpha [0.99989998]\n",
      "train_accuracy= 0.14 loss value = 46.3558\n",
      "nuclear_norm of iterates: w(t+1) = 0.335054 w(t) = 0.328437 s(t) = 0.00706562\n",
      "alpha [0.99989998]\n",
      "train_accuracy= 0.08 loss value = 46.4266\n",
      "nuclear_norm of iterates: w(t+1) = 0.342124 w(t) = 0.335054 s(t) = 0.00758658\n",
      "alpha [0.99989998]\n",
      "train_accuracy= 0.08 loss value = 46.3939\n",
      "nuclear_norm of iterates: w(t+1) = 0.348987 w(t) = 0.342124 s(t) = 0.0072026\n",
      "alpha [0.99989998]\n",
      "train_accuracy= 0.09 loss value = 46.4572\n",
      "nuclear_norm of iterates: w(t+1) = 0.356158 w(t) = 0.348987 s(t) = 0.00762528\n",
      "alpha [0.99989998]\n",
      "train_accuracy= 0.12 loss value = 46.5008\n",
      "nuclear_norm of iterates: w(t+1) = 0.363366 w(t) = 0.356158 s(t) = 0.0080397\n",
      "alpha [0.99989998]\n",
      "train_accuracy= 0.12 loss value = 46.4632\n",
      "nuclear_norm of iterates: w(t+1) = 0.370685 w(t) = 0.363366 s(t) = 0.00764526\n",
      "alpha [0.99989998]\n",
      "train_accuracy= 0.1 loss value = 46.4058\n",
      "nuclear_norm of iterates: w(t+1) = 0.378034 w(t) = 0.370685 s(t) = 0.00758748\n",
      "alpha [0.99989998]\n",
      "train_accuracy= 0.16 loss value = 46.5088\n",
      "nuclear_norm of iterates: w(t+1) = 0.384984 w(t) = 0.378034 s(t) = 0.00753956\n",
      "alpha [0.99989998]\n",
      "train_accuracy= 0.1 loss value = 46.4993\n",
      "nuclear_norm of iterates: w(t+1) = 0.392212 w(t) = 0.384984 s(t) = 0.00773021\n",
      "alpha [0.99989998]\n",
      "train_accuracy= 0.1 loss value = 46.5162\n",
      "nuclear_norm of iterates: w(t+1) = 0.399372 w(t) = 0.392212 s(t) = 0.0074916\n",
      "alpha [0.99989998]\n",
      "train_accuracy= 0.11 loss value = 46.4985\n",
      "nuclear_norm of iterates: w(t+1) = 0.406552 w(t) = 0.399372 s(t) = 0.00772036\n",
      "alpha [0.99989998]\n",
      "train_accuracy= 0.12 loss value = 46.4445\n",
      "nuclear_norm of iterates: w(t+1) = 0.412718 w(t) = 0.406552 s(t) = 0.00650332\n",
      "alpha [0.99989998]\n",
      "train_accuracy= 0.11 loss value = 46.4016\n",
      "nuclear_norm of iterates: w(t+1) = 0.41864 w(t) = 0.412718 s(t) = 0.00645562\n",
      "alpha [0.99989998]\n",
      "train_accuracy= 0.09 loss value = 46.6097\n",
      "nuclear_norm of iterates: w(t+1) = 0.426331 w(t) = 0.41864 s(t) = 0.00818385\n",
      "alpha [0.99989998]\n",
      "train_accuracy= 0.07 loss value = 46.7167\n",
      "nuclear_norm of iterates: w(t+1) = 0.434708 w(t) = 0.426331 s(t) = 0.00923272\n",
      "alpha [0.99989998]\n",
      "train_accuracy= 0.13 loss value = 46.5226\n",
      "nuclear_norm of iterates: w(t+1) = 0.442043 w(t) = 0.434708 s(t) = 0.00798281\n",
      "alpha [0.99989998]\n",
      "train_accuracy= 0.12 loss value = 46.7048\n",
      "nuclear_norm of iterates: w(t+1) = 0.449184 w(t) = 0.442043 s(t) = 0.00785986\n",
      "alpha [0.99989998]\n",
      "train_accuracy= 0.11 loss value = 46.5895\n",
      "nuclear_norm of iterates: w(t+1) = 0.456096 w(t) = 0.449184 s(t) = 0.00756765\n",
      "alpha [0.99989998]\n",
      "train_accuracy= 0.08 loss value = 46.6525\n",
      "nuclear_norm of iterates: w(t+1) = 0.463773 w(t) = 0.456096 s(t) = 0.00839877\n",
      "alpha [0.99989998]\n",
      "train_accuracy= 0.13 loss value = 46.8568\n",
      "nuclear_norm of iterates: w(t+1) = 0.471554 w(t) = 0.463773 s(t) = 0.00814846\n",
      "alpha [0.99989998]\n",
      "train_accuracy= 0.15 loss value = 46.5956\n",
      "nuclear_norm of iterates: w(t+1) = 0.477578 w(t) = 0.471554 s(t) = 0.00670348\n",
      "alpha [0.99989998]\n",
      "train_accuracy= 0.11 loss value = 46.4684\n",
      "nuclear_norm of iterates: w(t+1) = 0.483694 w(t) = 0.477578 s(t) = 0.00644948\n",
      "alpha [0.99989998]\n",
      "train_accuracy= 0.08 loss value = 46.532\n",
      "nuclear_norm of iterates: w(t+1) = 0.490229 w(t) = 0.483694 s(t) = 0.00693329\n",
      "alpha [0.99989998]\n",
      "train_accuracy= 0.11 loss value = 46.4981\n",
      "nuclear_norm of iterates: w(t+1) = 0.496543 w(t) = 0.490229 s(t) = 0.00667608\n",
      "alpha [0.99989998]\n",
      "train_accuracy= 0.12 loss value = 46.8901\n",
      "nuclear_norm of iterates: w(t+1) = 0.503951 w(t) = 0.496543 s(t) = 0.00781926\n",
      "alpha [0.99989998]\n",
      "train_accuracy= 0.09 loss value = 46.7832\n",
      "nuclear_norm of iterates: w(t+1) = 0.511219 w(t) = 0.503951 s(t) = 0.00813839\n",
      "alpha [0.99989998]\n",
      "train_accuracy= 0.11 loss value = 46.8694\n",
      "nuclear_norm of iterates: w(t+1) = 0.518584 w(t) = 0.511219 s(t) = 0.00806996\n",
      "alpha [0.99989998]\n",
      "train_accuracy= 0.14 loss value = 46.6674\n",
      "nuclear_norm of iterates: w(t+1) = 0.525747 w(t) = 0.518584 s(t) = 0.00751346\n",
      "alpha [0.99989998]\n",
      "train_accuracy= 0.09 loss value = 46.5613\n",
      "nuclear_norm of iterates: w(t+1) = 0.532349 w(t) = 0.525747 s(t) = 0.00684001\n",
      "alpha [0.99989998]\n",
      "train_accuracy= 0.12 loss value = 46.5328\n",
      "nuclear_norm of iterates: w(t+1) = 0.538132 w(t) = 0.532349 s(t) = 0.00649425\n",
      "alpha [0.99989998]\n",
      "train_accuracy= 0.09 loss value = 46.6391\n",
      "nuclear_norm of iterates: w(t+1) = 0.544555 w(t) = 0.538132 s(t) = 0.00726444\n",
      "alpha [0.99989998]\n",
      "train_accuracy= 0.1 loss value = 46.7002\n",
      "nuclear_norm of iterates: w(t+1) = 0.550926 w(t) = 0.544555 s(t) = 0.00699804\n",
      "alpha [0.99989998]\n",
      "train_accuracy= 0.14 loss value = 46.715\n",
      "nuclear_norm of iterates: w(t+1) = 0.557338 w(t) = 0.550926 s(t) = 0.00714893\n",
      "alpha [0.99989998]\n",
      "train_accuracy= 0.17 loss value = 46.7102\n",
      "nuclear_norm of iterates: w(t+1) = 0.563513 w(t) = 0.557338 s(t) = 0.0069645\n",
      "alpha [0.99989998]\n",
      "train_accuracy= 0.13 loss value = 46.697\n",
      "nuclear_norm of iterates: w(t+1) = 0.570016 w(t) = 0.563513 s(t) = 0.00708187\n",
      "alpha [0.99989998]\n",
      "train_accuracy= 0.11 loss value = 46.5715\n",
      "nuclear_norm of iterates: w(t+1) = 0.575978 w(t) = 0.570016 s(t) = 0.00637417\n",
      "alpha [0.99989998]\n",
      "train_accuracy= 0.13 loss value = 46.6819\n",
      "nuclear_norm of iterates: w(t+1) = 0.582397 w(t) = 0.575978 s(t) = 0.0069401\n",
      "alpha [0.99989998]\n",
      "train_accuracy= 0.13 loss value = 46.5727\n",
      "nuclear_norm of iterates: w(t+1) = 0.588454 w(t) = 0.582397 s(t) = 0.00675109\n",
      "alpha [0.99989998]\n",
      "train_accuracy= 0.09 loss value = 46.66\n",
      "nuclear_norm of iterates: w(t+1) = 0.594497 w(t) = 0.588454 s(t) = 0.00639472\n",
      "alpha [0.99989998]\n",
      "train_accuracy= 0.12 loss value = 46.8789\n",
      "nuclear_norm of iterates: w(t+1) = 0.600878 w(t) = 0.594497 s(t) = 0.00714733\n",
      "alpha [0.99989998]\n",
      "train_accuracy= 0.1 loss value = 46.6534\n",
      "nuclear_norm of iterates: w(t+1) = 0.607431 w(t) = 0.600878 s(t) = 0.00681198\n",
      "alpha [0.99989998]\n",
      "train_accuracy= 0.11 loss value = 46.7929\n",
      "nuclear_norm of iterates: w(t+1) = 0.613968 w(t) = 0.607431 s(t) = 0.00699189\n",
      "alpha [0.99989998]\n",
      "train_accuracy= 0.12 loss value = 46.8245\n",
      "nuclear_norm of iterates: w(t+1) = 0.620259 w(t) = 0.613968 s(t) = 0.0067438\n",
      "alpha [0.99989998]\n",
      "train_accuracy= 0.14 loss value = 46.9913\n",
      "nuclear_norm of iterates: w(t+1) = 0.627203 w(t) = 0.620259 s(t) = 0.00727219\n",
      "alpha [0.99989998]\n",
      "train_accuracy= 0.1 loss value = 46.9175\n",
      "nuclear_norm of iterates: w(t+1) = 0.634527 w(t) = 0.627203 s(t) = 0.00783469\n",
      "alpha [0.99989998]\n",
      "train_accuracy= 0.08 loss value = 47.1457\n",
      "nuclear_norm of iterates: w(t+1) = 0.642194 w(t) = 0.634527 s(t) = 0.0079917\n",
      "alpha [0.99989998]\n",
      "train_accuracy= 0.19 loss value = 47.1211\n",
      "nuclear_norm of iterates: w(t+1) = 0.649045 w(t) = 0.642194 s(t) = 0.00745594\n",
      "alpha [0.99989998]\n",
      "train_accuracy= 0.15 loss value = 46.8459\n",
      "nuclear_norm of iterates: w(t+1) = 0.655589 w(t) = 0.649045 s(t) = 0.00708799\n",
      "alpha [0.99989998]\n",
      "train_accuracy= 0.09 loss value = 46.7893\n",
      "nuclear_norm of iterates: w(t+1) = 0.662427 w(t) = 0.655589 s(t) = 0.00719366\n",
      "alpha [0.99989998]\n",
      "train_accuracy= 0.09 loss value = 46.8066\n",
      "nuclear_norm of iterates: w(t+1) = 0.668994 w(t) = 0.662427 s(t) = 0.00695827\n",
      "alpha [0.99989998]\n",
      "train_accuracy= 0.15 loss value = 46.855\n",
      "nuclear_norm of iterates: w(t+1) = 0.675216 w(t) = 0.668994 s(t) = 0.006489\n",
      "alpha [0.99989998]\n",
      "train_accuracy= 0.11 loss value = 46.7731\n",
      "nuclear_norm of iterates: w(t+1) = 0.681696 w(t) = 0.675216 s(t) = 0.00714052\n",
      "alpha [0.99989998]\n",
      "test_accuracy 0.1135\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in range(100):\n",
    "        batch = mnist.train.next_batch(100)\n",
    "        batch2 = batch[:]\n",
    "        feed_dict = {x: np.transpose(batch[0]), y_true: np.transpose(batch[1])}\n",
    "        train_accuracy, loss_, gv_, W2_ = sess.run([accuracy, loss, gv_cgd_nn, W], feed_dict)\n",
    "        w1_cgd_nn_, w0_cgd_nn_, s0_cgd_nn_, st_, st_r_, M_ = sess.run([w1_cgd_nn, w0_cgd_nn, s0_cgd_nn, st, st_r, M], feed_dict)\n",
    "        alpha_ = sess.run([alpha], feed_dict)\n",
    "            \n",
    "        if i % 1 == 0:\n",
    "            print('train_accuracy=', train_accuracy, 'loss value =',loss_)\n",
    "            print('nuclear_norm of iterates: w(t+1) =', LA.norm(w1_cgd_nn_), 'w(t) =', LA.norm(w0_cgd_nn_), 's(t) =', LA.norm(s0_cgd_nn_))\n",
    "            print('alpha', alpha_)\n",
    "        sess.run(optimizer_gv_cgd_nn, feed_dict)\n",
    "    \n",
    "    feed_dict={x: np.transpose(mnist.test.images), y_true: np.transpose(mnist.test.labels)}\n",
    "    test_accuracy = sess.run(accuracy, feed_dict)\n",
    "    print('test_accuracy', test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23.973583"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LA.norm(M_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23.973591"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LA.norm(st_r_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False, False, False, ...,  True,  True,  True],\n",
       "       [False, False, False, ...,  True,  True,  True],\n",
       "       [False, False, False, ...,  True,  True,  True],\n",
       "       ..., \n",
       "       [False, False, False, ...,  True,  True,  True],\n",
       "       [False, False, False, ...,  True,  True,  True],\n",
       "       [False, False, False, ...,  True,  True,  True]], dtype=bool)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
