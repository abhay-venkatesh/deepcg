{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from numpy import linalg as LA\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(10), Dimension(None)])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[784, None])\n",
    "y_true = tf.placeholder(tf.float32, shape=[10, None])\n",
    "W = tf.Variable(tf.zeros([10,784]))\n",
    "b = tf.Variable(tf.zeros([10,1]))\n",
    "y_pred = tf.matmul(W, x) + b\n",
    "y_pred.get_shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_true, logits=y_pred))\n",
    "# optimzr = tf.train.AdamOptimizer(1e-4).minimize(loss)\n",
    "\n",
    "# correct_prediction = tf.equal(tf.argmax(y_pred, 0), tf.argmax(y_true, 0))\n",
    "# accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tf_frobenius_norm(M):\n",
    "    return tf.reduce_sum(M ** 2) ** 0.5\n",
    "\n",
    "# to implement nuclear norm\n",
    "def tf_nuclear_norm(M):\n",
    "    return 1\n",
    "\n",
    "def Cgd_Fn(grad, wt):\n",
    "    return ((1 - alpha ) / alpha) * (wt - lam1 * grad / tf_frobenius_norm(grad))\n",
    "\n",
    "def Cgd_Nn(grad, wt):\n",
    "    return ((1 - alpha ) / alpha) * (wt - lam2 * tf_nuclear_norm(grad))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_true, logits=y_pred))\n",
    "\n",
    "# hyper-parameters\n",
    "alpha = tf.placeholder_with_default(tf.constant(0.999), tf.constant(0.999).shape)\n",
    "lam1 = tf.placeholder_with_default(tf.constant(100.0), tf.constant(100.0).shape)\n",
    "lam2 = tf.placeholder_with_default(tf.constant(100.0), tf.constant(100.0).shape)\n",
    "\n",
    "# Gradient Descent optimizer\n",
    "opt = tf.train.GradientDescentOptimizer(learning_rate = alpha)\n",
    "\n",
    "# Compute the gradients for a list of variables.\n",
    "grads_and_vars = opt.compute_gradients(loss)\n",
    "\n",
    "# Normal GD update\n",
    "gv_sgd = [(gv[0], gv[1]) for gv in grads_and_vars]\n",
    "optimizer_gv_sgd = opt.apply_gradients(gv_sgd)\n",
    "\n",
    "# CGD with FN\n",
    "gv_cgd_fn = [(Cgd_Fn(gv[0], gv[1]), gv[1]) for gv in grads_and_vars]\n",
    "optimizer_gv_cgd_fn = opt.apply_gradients(gv_cgd_fn)\n",
    "a = grads_and_vars[0][0]\n",
    "b = tf_frobenius_norm(grads_and_vars[0][0])\n",
    "c = grads_and_vars[0][0] / tf_frobenius_norm(grads_and_vars[0][0])\n",
    "d = Cgd_Fn(grads_and_vars[0][0], grads_and_vars[0][1])\n",
    "e = grads_and_vars[0][1]\n",
    "f = alpha #((1 - alpha ) / alpha)#*(grads_and_vars[0][1] - lam1 * grads_and_vars[0][0] / tf_frobenius_norm(grads_and_vars[0][0]))\n",
    "\n",
    "\n",
    "# CGD with NN\n",
    "gv_cgd_nn = [(Cgd_Nn(gv[0], gv[1]), gv[1]) for gv in grads_and_vars]\n",
    "optimizer_gv_cgd_Nn = opt.apply_gradients(gv_cgd_nn)\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(y_pred, 0), tf.argmax(y_true, 0))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_accuracy 0.07 46.0517\n",
      "frob_nrom 21.5567 21.5567 1.0 0.100099 0.100099 0.0 0.999\n",
      "train_accuracy 0.0 147.866\n",
      "frob_nrom 23.3375 23.3375 1.0 0.0923332 0.0923332 8.71444 0.999\n",
      "train_accuracy 0.0 285.628\n",
      "frob_nrom 23.6118 23.6118 1.0 0.0851485 0.0851485 16.5792 0.999\n",
      "train_accuracy 0.0 363.602\n",
      "frob_nrom 21.5782 21.5782 1.0 0.0787868 0.0787868 23.7374 0.999\n",
      "train_accuracy 0.0 520.301\n",
      "frob_nrom 23.9385 23.9385 1.0 0.0736236 0.0736236 30.2167 0.999\n",
      "train_accuracy 0.01 624.777\n",
      "frob_nrom 23.4221 23.4221 1.0 0.0692606 0.0692606 36.0751 0.999\n",
      "train_accuracy 0.01 653.222\n",
      "frob_nrom 21.6787 21.6787 1.0 0.0643617 0.0643617 41.3617 0.999\n",
      "train_accuracy 0.0 753.081\n",
      "frob_nrom 23.3796 23.3796 1.0 0.062449 0.062449 46.1536 0.999\n",
      "train_accuracy 0.0 818.315\n",
      "frob_nrom 23.1236 23.1236 1.0 0.0583339 0.0583339 50.4769 0.999\n",
      "train_accuracy 0.02 820.126\n",
      "frob_nrom 21.9488 21.9488 1.0 0.0544072 0.0544072 54.3494 0.999\n",
      "train_accuracy 0.0 902.093\n",
      "frob_nrom 22.4067 22.4067 1.0 0.0570773 0.0570773 57.8884 0.999\n",
      "train_accuracy 0.0 940.762\n",
      "frob_nrom 23.3408 23.3408 1.0 0.0516693 0.0516693 61.067 0.999\n",
      "train_accuracy 0.01 906.513\n",
      "frob_nrom 21.2572 21.2572 1.0 0.0461013 0.0461013 63.9649 0.999\n",
      "train_accuracy 0.0 1075.49\n",
      "frob_nrom 22.8216 22.8216 1.0 0.0488325 0.0488325 66.5898 0.999\n",
      "train_accuracy 0.0 1116.36\n",
      "frob_nrom 22.8215 22.8215 1.0 0.0433793 0.0433793 68.972 0.999\n",
      "train_accuracy 0.0 1089.85\n",
      "frob_nrom 23.254 23.254 1.0 0.0475013 0.0475013 71.1203 0.999\n",
      "train_accuracy 0.01 1116.16\n",
      "frob_nrom 22.543 22.543 1.0 0.0449113 0.0449113 73.073 0.999\n",
      "train_accuracy 0.0 1193.16\n",
      "frob_nrom 23.7308 23.7308 1.0 0.045793 0.045793 74.8304 0.999\n",
      "train_accuracy 0.0 1068.09\n",
      "frob_nrom 21.8307 21.8307 1.0 0.0379884 0.0379884 76.4142 0.999\n",
      "train_accuracy 0.01 1288.12\n",
      "frob_nrom 23.0348 23.0348 1.0 0.0453302 0.0453302 77.867 0.999\n",
      "train_accuracy 0.01 1240.2\n",
      "frob_nrom 22.7686 22.7686 1.0 0.0430874 0.0430874 79.1601 0.999\n",
      "train_accuracy 0.01 1232.27\n",
      "frob_nrom 22.3755 22.3755 1.0 0.0484328 0.0484328 80.3454 0.999\n",
      "train_accuracy 0.01 1247.51\n",
      "frob_nrom 23.6403 23.6403 1.0 0.0452263 0.0452263 81.398 0.999\n",
      "train_accuracy 0.01 1316.52\n",
      "frob_nrom 23.1308 23.1308 1.0 0.0421347 0.0421347 82.3447 0.999\n",
      "train_accuracy 0.0 1355.05\n",
      "frob_nrom 23.3053 23.3053 1.0 0.0377837 0.0377837 83.2327 0.999\n",
      "train_accuracy 0.01 1409.16\n",
      "frob_nrom 23.3777 23.3777 1.0 0.0455357 0.0455357 83.9826 0.999\n",
      "train_accuracy 0.0 1384.0\n",
      "frob_nrom 22.4544 22.4544 1.0 0.0431181 0.0431181 84.7039 0.999\n",
      "train_accuracy 0.01 1385.74\n",
      "frob_nrom 22.362 22.362 1.0 0.0421695 0.0421695 85.3516 0.999\n",
      "train_accuracy 0.02 1241.76\n",
      "frob_nrom 21.6262 21.6262 1.0 0.0346941 0.0346941 85.9274 0.999\n",
      "train_accuracy 0.0 1404.93\n",
      "frob_nrom 22.233 22.233 1.0 0.0380893 0.0380893 86.4587 0.999\n",
      "train_accuracy 0.0 1378.8\n",
      "frob_nrom 24.5904 24.5904 1.0 0.0492453 0.0492453 86.9606 0.999\n",
      "train_accuracy 0.0 1382.44\n",
      "frob_nrom 23.0379 23.0379 1.0 0.0416437 0.0416437 87.392 0.999\n",
      "train_accuracy 0.01 1585.93\n",
      "frob_nrom 24.2406 24.2406 1.0 0.0437897 0.0437897 87.779 0.999\n",
      "train_accuracy 0.02 1428.98\n",
      "frob_nrom 23.2712 23.2712 1.0 0.0400945 0.0400945 88.1314 0.999\n",
      "train_accuracy 0.01 1379.36\n",
      "frob_nrom 24.429 24.429 1.0 0.0425058 0.0425058 88.4529 0.999\n",
      "train_accuracy 0.01 1471.32\n",
      "frob_nrom 23.4049 23.4049 1.0 0.0377815 0.0377815 88.7626 0.999\n",
      "train_accuracy 0.0 1389.82\n",
      "frob_nrom 23.3254 23.3254 1.0 0.0477897 0.0477897 89.0473 0.999\n",
      "train_accuracy 0.0 1406.94\n",
      "frob_nrom 22.5898 22.5898 1.0 0.039858 0.039858 89.2564 0.999\n",
      "train_accuracy 0.01 1326.08\n",
      "frob_nrom 22.1116 22.1116 1.0 0.0319896 0.0319896 89.4483 0.999\n",
      "train_accuracy 0.02 1435.09\n",
      "frob_nrom 21.5703 21.5703 1.0 0.0319189 0.0319189 89.6276 0.999\n",
      "train_accuracy 0.0 1599.38\n",
      "frob_nrom 22.495 22.495 1.0 0.0333664 0.0333664 89.8412 0.999\n",
      "train_accuracy 0.01 1490.94\n",
      "frob_nrom 24.7963 24.7963 1.0 0.0473309 0.0473309 90.037 0.999\n",
      "train_accuracy 0.0 1379.43\n",
      "frob_nrom 21.7171 21.7171 1.0 0.0332232 0.0332232 90.1533 0.999\n",
      "train_accuracy 0.0 1399.26\n",
      "frob_nrom 21.7676 21.7676 1.0 0.03795 0.03795 90.3005 0.999\n",
      "train_accuracy 0.0 1369.5\n",
      "frob_nrom 22.4016 22.4016 1.0 0.0374264 0.0374264 90.426 0.999\n",
      "train_accuracy 0.0 1348.35\n",
      "frob_nrom 22.8135 22.8135 1.0 0.0396889 0.0396889 90.5646 0.999\n",
      "train_accuracy 0.0 1452.5\n",
      "frob_nrom 21.4225 21.4225 1.0 0.0384154 0.0384154 90.6961 0.999\n",
      "train_accuracy 0.0 1371.71\n",
      "frob_nrom 22.0486 22.0486 1.0 0.0419699 0.0419699 90.7662 0.999\n",
      "train_accuracy 0.0 1357.68\n",
      "frob_nrom 22.9249 22.9249 1.0 0.0428507 0.0428507 90.862 0.999\n",
      "train_accuracy 0.03 1455.26\n",
      "frob_nrom 21.6767 21.6767 1.0 0.0358988 0.0358988 90.9214 0.999\n",
      "train_accuracy 0.0 1624.28\n",
      "frob_nrom 24.7545 24.7545 1.0 0.0374991 0.0374991 90.9967 0.999\n",
      "train_accuracy 0.0 1605.56\n",
      "frob_nrom 23.6538 23.6538 1.0 0.0388646 0.0388646 91.0534 0.999\n",
      "train_accuracy 0.0 1401.1\n",
      "frob_nrom 22.4936 22.4936 1.0 0.034711 0.034711 91.0914 0.999\n",
      "train_accuracy 0.0 1341.03\n",
      "frob_nrom 21.6319 21.6319 1.0 0.0376004 0.0376004 91.1359 0.999\n",
      "train_accuracy 0.0 1462.81\n",
      "frob_nrom 22.5268 22.5268 1.0 0.0352761 0.0352761 91.1904 0.999\n",
      "train_accuracy 0.01 1396.6\n",
      "frob_nrom 22.9854 22.9854 1.0 0.0445714 0.0445714 91.2369 0.999\n",
      "train_accuracy 0.0 1485.36\n",
      "frob_nrom 22.9259 22.9259 1.0 0.0340036 0.0340036 91.263 0.999\n",
      "train_accuracy 0.0 1373.02\n",
      "frob_nrom 23.4762 23.4762 1.0 0.0418365 0.0418365 91.2934 0.999\n",
      "train_accuracy 0.01 1606.9\n",
      "frob_nrom 23.1079 23.1079 1.0 0.0384678 0.0384678 91.3433 0.999\n",
      "train_accuracy 0.01 1402.61\n",
      "frob_nrom 21.9701 21.9701 1.0 0.0361754 0.0361754 91.3701 0.999\n",
      "train_accuracy 0.0 1474.0\n",
      "frob_nrom 23.1255 23.1255 1.0 0.0434373 0.0434373 91.3957 0.999\n",
      "train_accuracy 0.02 1438.17\n",
      "frob_nrom 21.8586 21.8586 1.0 0.0338958 0.0338958 91.3965 0.999\n",
      "train_accuracy 0.0 1324.14\n",
      "frob_nrom 22.1466 22.1466 1.0 0.0387374 0.0387374 91.4276 0.999\n",
      "train_accuracy 0.0 1427.21\n",
      "frob_nrom 23.4489 23.4489 1.0 0.0456323 0.0456323 91.4359 0.999\n",
      "train_accuracy 0.0 1471.94\n",
      "frob_nrom 23.0041 23.0041 1.0 0.0386432 0.0386432 91.4393 0.999\n",
      "train_accuracy 0.0 1361.54\n",
      "frob_nrom 21.4101 21.4101 1.0 0.0431437 0.0431437 91.431 0.999\n",
      "train_accuracy 0.02 1464.6\n",
      "frob_nrom 23.0797 23.0797 1.0 0.0468649 0.0468649 91.4312 0.999\n",
      "train_accuracy 0.01 1451.33\n",
      "frob_nrom 23.0859 23.0859 1.0 0.0419642 0.0419642 91.4272 0.999\n",
      "train_accuracy 0.01 1507.26\n",
      "frob_nrom 23.508 23.508 1.0 0.0403087 0.0403087 91.4354 0.999\n",
      "train_accuracy 0.0 1557.28\n",
      "frob_nrom 23.254 23.254 1.0 0.045811 0.045811 91.4363 0.999\n",
      "train_accuracy 0.0 1367.96\n",
      "frob_nrom 22.7065 22.7065 1.0 0.0375451 0.0375451 91.4198 0.999\n",
      "train_accuracy 0.02 1583.63\n",
      "frob_nrom 22.4545 22.4545 1.0 0.0372114 0.0372114 91.4212 0.999\n",
      "train_accuracy 0.0 1606.67\n",
      "frob_nrom 24.4174 24.4174 1.0 0.0419292 0.0419292 91.4173 0.999\n",
      "train_accuracy 0.01 1400.79\n",
      "frob_nrom 21.5876 21.5876 1.0 0.0363644 0.0363644 91.4436 0.999\n",
      "train_accuracy 0.0 1399.68\n",
      "frob_nrom 23.1119 23.1119 1.0 0.040964 0.040964 91.4494 0.999\n",
      "train_accuracy 0.0 1370.16\n",
      "frob_nrom 22.036 22.036 1.0 0.0347411 0.0347411 91.4386 0.999\n",
      "train_accuracy 0.0 1455.33\n",
      "frob_nrom 22.8038 22.8038 1.0 0.0433931 0.0433931 91.4688 0.999\n",
      "train_accuracy 0.0 1470.52\n",
      "frob_nrom 23.3044 23.3044 1.0 0.0427638 0.0427638 91.4795 0.999\n",
      "train_accuracy 0.01 1449.31\n",
      "frob_nrom 21.6612 21.6612 1.0 0.0348345 0.0348345 91.4605 0.999\n",
      "train_accuracy 0.02 1355.26\n",
      "frob_nrom 21.3077 21.3077 1.0 0.0333553 0.0333553 91.4966 0.999\n",
      "train_accuracy 0.03 1360.04\n",
      "frob_nrom 21.7429 21.7429 1.0 0.0400697 0.0400697 91.4954 0.999\n",
      "train_accuracy 0.01 1381.26\n",
      "frob_nrom 21.5067 21.5067 1.0 0.0350086 0.0350086 91.4907 0.999\n",
      "train_accuracy 0.0 1489.5\n",
      "frob_nrom 23.2677 23.2677 1.0 0.045219 0.045219 91.4514 0.999\n",
      "train_accuracy 0.01 1615.29\n",
      "frob_nrom 22.7904 22.7904 1.0 0.0334561 0.0334561 91.46 0.999\n",
      "train_accuracy 0.0 1379.84\n",
      "frob_nrom 21.9915 21.9914 1.0 0.0380713 0.0380713 91.478 0.999\n",
      "train_accuracy 0.0 1631.43\n",
      "frob_nrom 23.2398 23.2398 1.0 0.038455 0.038455 91.4996 0.999\n",
      "train_accuracy 0.01 1476.55\n",
      "frob_nrom 22.5192 22.5192 1.0 0.0362547 0.0362547 91.5143 0.999\n",
      "train_accuracy 0.0 1456.96\n",
      "frob_nrom 22.7081 22.7081 1.0 0.0379964 0.0379964 91.5242 0.999\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in range(100000):\n",
    "        batch = mnist.train.next_batch(100)\n",
    "        feed_dict = {x: np.transpose(batch[0]), y_true: np.transpose(batch[1])}\n",
    "        train_accuracy, loss_, g_, W_ = sess.run([accuracy, loss, gv_cgd_fn, W], feed_dict)\n",
    "        a_,b_,c_,d_,e_,f_ = sess.run([a,b,c,d,e,f], feed_dict)\n",
    "            \n",
    "        if i % 100 == 0:\n",
    "            print('train_accuracy', train_accuracy, loss_)\n",
    "            print('frob_nrom', LA.norm(a_), b_, LA.norm(c_), LA.norm(g_[0][0]), LA.norm(d_), LA.norm(e_), LA.norm(f_))\n",
    "        sess.run(optimizer_gv_cgd_fn, feed_dict)\n",
    "    \n",
    "    feed_dict={x: np.transpose(mnist.test.images), y_true: np.transpose(mnist.test.labels)}\n",
    "    test_accuracy = sess.run(accuracy, feed_dict)\n",
    "    print('test_accuracy', test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(type(grads_and_vars[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  4],\n",
       "       [ 9, 16],\n",
       "       [25, 36]], dtype=int32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.constant([[1,2],[3,4],[5,6]])\n",
    "b = a**2\n",
    "tf.Session().run(b)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
